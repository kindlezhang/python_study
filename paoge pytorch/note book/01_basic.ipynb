{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb684c0",
   "metadata": {},
   "source": [
    "# basic knowledge\n",
    "\n",
    "## DNN结构\n",
    "\n",
    "输入层 隐藏层 输出层\n",
    "输入层是一些图片或者矩阵\n",
    "同层的神经单元之间相互独立，不同层之间的神经元全连接\n",
    "\n",
    "## DNN单元\n",
    "\n",
    "神经元的数学表达式：\n",
    "a = h(w * x + b)\n",
    "b是bias, w是权重矩阵，x是输入矩阵，a是下一个神经元，h是<mark>激活函数</mark>\n",
    "本质上就是调参的过程，不管是分类还是回归都是找出每个神经元最优的w，b，h（模型确定的情况下），使x不变的情况下y最接近真实值\n",
    "\n",
    "## 激活函数\n",
    "\n",
    "h(x)可以使线性也可以是非线性\n",
    "h(x) = cx\n",
    "y(x) = h(h(h(x))) 就是一个3层神经网络\n",
    "相当于 h(x) = c ** 3 * x ，那其实本质上还是一层，那效果就不好了，因为隐藏层数应该越深越好（也不尽然，resnet就是为了防止过拟合）\n",
    "\n",
    "### sigmoid 激活函数\n",
    "\n",
    "$函数公式在此$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e41c735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "604465c8",
   "metadata": {},
   "source": [
    "图像在此\n",
    "\n",
    "- 优点：简单，适合做分类任务（输出层的激活函数）\n",
    "- 缺点：\n",
    "1. 反向传播训练时候有梯度消失的问题 (w,b就不更新了)\n",
    "2. 输出值区间（0,1） 关于0不对称\n",
    "3. 梯度更新在不同方向走得太远，使得优化难度增大，训练耗时"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf3994e",
   "metadata": {},
   "source": [
    "### Tanh 激活函数 （双曲正切）\n",
    "\n",
    "$函数公式在此$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c4874c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b08b5ba",
   "metadata": {},
   "source": [
    "图像在此\n",
    "\n",
    "- 优点：\n",
    "1. 解决了Sigmoid函数输出值非0对称的问题\n",
    "2. 训练速度快，更容易收敛\n",
    "- 缺点：\n",
    "1. 梯度消失的问题\n",
    "2. 与Sigmoid函数类似"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43617f",
   "metadata": {},
   "source": [
    "### ReLU函数 \n",
    "\n",
    "$公式$ 本质上是分段函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19a922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02536eac",
   "metadata": {},
   "source": [
    "- 优点：\n",
    "1. 解决梯度消失的问题\n",
    "2. 计算更为简单，没有T和S的指数运算\n",
    "- 缺点：\n",
    "会有神经元死亡的问题"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
