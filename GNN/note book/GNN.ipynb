{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41189c16",
   "metadata": {},
   "source": [
    "This notebook is a textbook for A tutorial on spectral clustering, I set some examples to help understand the therom.\n",
    "\n",
    "Spectral clustering is the most popular clustering algorithm who always outperform traditional clustering algorithms such as the k-means algorithm.\n",
    "\n",
    "clustering belongs to unsupervised learning. \n",
    "\n",
    "to better understand the mathematical objects used by spectral clustering, we should know similarity graphs and graph Laplacians\n",
    "\n",
    "1. G = (V, E)\n",
    "2. the degree of a vertex v_i, the degree matrix D\n",
    "3. adjacency matrix W = (w_ij)\n",
    "   \n",
    "the size of a subset:\n",
    "1. |A| = the number of vertices in A\n",
    "2. vol(A) = $\\sum_{i\\in A} d_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6866e4",
   "metadata": {},
   "source": [
    "# similarity graphs\n",
    "\n",
    "1. ε-neighborhood\n",
    "2. k-nearest neighbor graphs\n",
    "3. the fully connected graph "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad598f",
   "metadata": {},
   "source": [
    "# Graph Laplacians and their basic properties\n",
    "\n",
    "assume: G is an undirected, weighted graph with weight matrix W. Eigenvectors of a matrix don't have to be normalized.\n",
    "\n",
    "\n",
    "## The unnormalized graph Laplacian\n",
    "\n",
    "L = D - W \n",
    "\n",
    "we have the proposition of L (1-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646329a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplacian matrix L:\n",
      " [[ 1. -1.  0.  0.]\n",
      " [-1.  1.  0.  0.]\n",
      " [ 0.  0.  2. -2.]\n",
      " [ 0.  0. -2.  2.]]\n",
      "\n",
      "Eigenvalues: [0. 0. 2. 4.]\n",
      "\n",
      "Eigenvectors (columns):\n",
      " [[-0.7071 -0.     -0.7071  0.    ]\n",
      " [-0.7071 -0.      0.7071  0.    ]\n",
      " [-0.     -0.7071  0.     -0.7071]\n",
      " [-0.     -0.7071  0.      0.7071]]\n",
      "\n",
      "Zero-eigenvalue eigenspace (spanned by first two eigenvectors):\n",
      "[[-0.7071 -0.    ]\n",
      " [-0.7071 -0.    ]\n",
      " [-0.     -0.7071]\n",
      " [-0.     -0.7071]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import eigh\n",
    "import sympy as sp\n",
    "\n",
    "# assume two completely independent connected components A-B and C-D， we have k=2 connected components, L is a block diagonal matrix\n",
    "# W matrix\n",
    "\n",
    "W = np.array([\n",
    "    [0, 1, 0, 0],\n",
    "    [1, 0, 0, 0],\n",
    "    [0, 0, 0, 2],\n",
    "    [0, 0, 2, 0]\n",
    "], dtype=float)\n",
    "\n",
    "# D matrix\n",
    "\n",
    "D = np.diag(W.sum(axis=1))\n",
    "\n",
    "# L matrix\n",
    "\n",
    "L = D - W\n",
    "\n",
    "print(\"Laplacian matrix L:\\n\", L)\n",
    "\n",
    "# eigenvalues and eigenvectors of L\n",
    "eigvals, eigvecs = eigh(L)  # eigh is used for symmetric matrices\n",
    "print(\"\\nEigenvalues:\", eigvals)\n",
    "\n",
    "# eigenvectors\n",
    "print(\"\\nEigenvectors (columns):\\n\", np.round(eigvecs, 4))\n",
    "\n",
    "# Check for zero eigenvalues\n",
    "print(\"\\nZero-eigenvalue eigenspace (spanned by first two eigenvectors):\")\n",
    "# all rows and the first two columns of eigvecs\n",
    "print(np.round(eigvecs[:, :2], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda00043",
   "metadata": {},
   "source": [
    "we can find we have two 0 eigenvalue which is equal to the number of k. for first 0, the eigenvector is (1,1,0,0) which is the indicator vector.\n",
    "\n",
    "the result is after normalization, we can also calculate by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67cf9de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam**2*(lam - 4)*(lam - 2)\n",
      "Eigenvectors for λ=0:\n",
      "Matrix([[1], [1], [0], [0]])\n",
      "Matrix([[0], [0], [1], [1]])\n",
      "\n",
      "Eigenvectors for λ=2:\n",
      "Matrix([[-1], [1], [0], [0]])\n",
      "\n",
      "Eigenvectors for λ=4:\n",
      "Matrix([[0], [0], [-1], [1]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sympy as sp\n",
    "\n",
    "# define L\n",
    "L = sp.Matrix([[1, -1, 0, 0],\n",
    "               [-1, 1, 0, 0],\n",
    "               [0, 0, 2, -2],\n",
    "               [0, 0, -2, 2]])\n",
    "\n",
    "# The eigenvalue problem Lx = λx\n",
    "# det(L−λI)=det(A−λI)⋅det(B−λI),\n",
    "lam = sp.symbols('lam')\n",
    "I = sp.eye(L.shape[0])  \n",
    "det_poly = (L - lam*I).det()\n",
    "print(sp.factor(det_poly))\n",
    "\n",
    "\n",
    "\n",
    "# for egienvalue = 0, indicators of the connected components\n",
    "# (1,1,0,0) and (0,0,1,1)\n",
    "\n",
    "for lam in [0, 2, 4]:\n",
    "    M = L - lam*I\n",
    "    x = M.nullspace()   # returns the null space of M\n",
    "    print(f\"Eigenvectors for λ={lam}:\")\n",
    "    for vec in x:\n",
    "        print(vec)      # vec is a 4*1 column vector\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e504f9",
   "metadata": {},
   "source": [
    "We can get the same result calculating by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f70e16b",
   "metadata": {},
   "source": [
    "## The normalized graph Laplacians\n",
    "\n",
    "1. symmetric normalized Laplacian: $L_{sym}$\n",
    "2. random walk normalized Laplacian: $L_{rw}$\n",
    "\n",
    "we can get similar result by running a code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326729c7",
   "metadata": {},
   "source": [
    "# Spectral clustering algorithms\n",
    "\n",
    "We measure their pairwise similarities sij= s(xi , xj) by some similarity function which is symmetric and non-negative.\n",
    "similarity matrix: S(s_ij)\n",
    "\n",
    "we have the steps:\n",
    "1. get similarity graph (fully/knn/e-neighbourhood)\n",
    "2. get W and D matrix\n",
    "3. choose L or L_rw/L_sym\n",
    "4. use k-means\n",
    "\n",
    "to better understand the plot showed in papaer, we can generate data and make a simple simulation by running code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad211d",
   "metadata": {},
   "source": [
    "# Graph cut point of view\n",
    "\n",
    "1. RatioCut: using |A| relaxing RatioCut leads to unnormalized spectral clustering\n",
    "2. normalized cut Ncut: using vol(A) relaxing Ncut leads to normalized spectral clus-tering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "657c55b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mincut(P1) = 2.0\n",
      "mincut(P2) = 10.0\n",
      "RatioCut(P1) = 1.3333333333333333\n",
      "RatioCut(P2) = 12.0\n",
      "Ncut(P1) = 0.36363636363636365\n",
      "Ncut(P2) = 1.9090909090909092\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# adjacency matrix W\n",
    "W = np.zeros((6,6))\n",
    "# A completely connected graph weight 5\n",
    "for i in [0,1,2]:\n",
    "    for j in [0,1,2]:\n",
    "        if i<j: W[i,j]=W[j,i]=5\n",
    "# B completely connected graph weight 5\n",
    "for i in [3,4,5]:\n",
    "    for j in [3,4,5]:\n",
    "        if i<j: W[i,j]=W[j,i]=5\n",
    "# some weak connections between A and B weight 1\n",
    "W[2,3]=W[3,2]=1  # (3,4)\n",
    "W[1,4]=W[4,1]=1  # (2,5)\n",
    "\n",
    "def cut_weight(W, A):\n",
    "    A = set(A)\n",
    "    B = set(range(W.shape[0])) - A\n",
    "    return W[np.ix_(list(A), list(B))].sum()\n",
    "\n",
    "def ratio_cut(W, parts):\n",
    "    return sum(cut_weight(W, P)/len(P) for P in parts)\n",
    "\n",
    "def normalized_cut(W, parts):\n",
    "    D = np.diag(W.sum(axis=1))\n",
    "    D_inv = np.linalg.inv(D)\n",
    "    W_norm = D_inv @ W\n",
    "    return sum(cut_weight(W_norm, P) for P in parts)\n",
    "\n",
    "P1 = [ [0,1,2], [3,4,5] ]       # {1,2,3} vs {4,5,6}\n",
    "P2 = [ [0], [1,2,3,4,5] ]       # {1} vs {2,3,4,5,6}\n",
    "\n",
    "print(\"mincut(P1) =\", cut_weight(W, P1[0]))  # 2.0 (if there are multiple cuts, return the half of sum)\n",
    "print(\"mincut(P2) =\", cut_weight(W, P2[0]))  # 10.0\n",
    "print(\"RatioCut(P1) =\", ratio_cut(W, P1))  # ~1.3333\n",
    "print(\"RatioCut(P2) =\", ratio_cut(W, P2))  # 12.0\n",
    "print(\"Ncut(P1) =\", normalized_cut(W, P1))  # ~0.3636\n",
    "print(\"Ncut(P2) =\", normalized_cut(W, P2))  # ~1.9091\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250533e3",
   "metadata": {},
   "source": [
    "# Random walks point of view"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8a48fe",
   "metadata": {},
   "source": [
    "# Perturbation theory point of view"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
